## Download Ollama and Choose a Model

1. Visit [Ollama](https://ollama.com/) to download Ollama.
2. Go to the [Ollama Library](https://ollama.com/library) to choose a model.

##  Use Llama3

For using llama3, follow these steps:

1. Visit the [Llama3 Blog](https://ollama.com/blog/llama3) for usage instructions.
2. To download llama3, open a terminal and type: `ollama pull llama3`.
3. To check the list of models, in terminal type: `ollama list`.
4. To run the model, type: `ollama run llama3`.
5. If you would like to see the output of the model for debugging, you can run ollama as a server by typing: `ollama serve`.
